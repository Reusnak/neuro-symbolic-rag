import os
import shutil
import pickle
import uuid
import networkx as nx
from typing import Iterator, List, Optional, Sequence, Tuple

# æ ¸å¿ƒä¾èµ– (é€‚é… LangChain 0.3+)
from langchain_core.stores import ByteStore
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_community.retrievers import BM25Retriever

import config
from splitter import TextSplitterFactory

# --- 1. è½»é‡åŒ–æœ¬åœ°å­˜å‚¨å­˜å‚¨çˆ¶æ–‡æ¡£ ---
class LocalFileStore(ByteStore):
    def __init__(self, root_path: str):
        self.root_path = root_path
        os.makedirs(root_path, exist_ok=True)

    def mget(self, keys: Sequence[str]) -> List[Optional[bytes]]:
        results = []
        for k in keys:
            path = os.path.join(self.root_path, k)
            results.append(open(path, "rb").read() if os.path.exists(path) else None)
        return results

    def mset(self, key_value_pairs: Sequence[Tuple[str, bytes]]) -> None:
        for k, v in key_value_pairs:
            with open(os.path.join(self.root_path, k), "wb") as f:
                f.write(v)

    def mdelete(self, keys: Sequence[str]) -> None:
        for k in keys:
            path = os.path.join(self.root_path, k)
            if os.path.exists(path): os.remove(path)

    def yield_keys(self, prefix: Optional[str] = None) -> Iterator[str]:
        for k in os.listdir(self.root_path):
            if prefix is None or k.startswith(prefix): yield k

# --- 2. æ‰‹å†™çˆ¶å­æ–‡æ¡£ç®¡ç†é€»è¾‘ ---
class SimpleParentRetriever:
    def __init__(self, vectorstore, docstore, child_splitter, parent_splitter):
        self.vectorstore = vectorstore
        self.docstore = docstore
        self.child_splitter = child_splitter
        self.parent_splitter = parent_splitter
        self.id_key = "doc_id"

    def add_documents(self, documents: List[Document]):
        for doc in documents:
            # ç”Ÿæˆè¯­ä¹‰å®Œæ•´çš„çˆ¶å— (ç”¨äºæœ€ç»ˆé˜…è¯»)
            parent_docs = self.parent_splitter.split_documents([doc])
            for p_doc in parent_docs:
                _id = str(uuid.uuid4())
                # å­˜å‚¨åŸå§‹çˆ¶å—
                self.docstore.mset([(_id, pickle.dumps(p_doc))])
                # ç”Ÿæˆç»†é¢—ç²’åº¦å­å— (ç”¨äºç²¾å‡†åŒ¹é…)
                child_docs = self.child_splitter.split_documents([p_doc])
                for c_doc in child_docs:
                    c_doc.metadata[self.id_key] = _id
                self.vectorstore.add_documents(child_docs)

# --- 3. å­˜å‚¨ç®¡ç†å™¨ (æ ¸å¿ƒ) ---
class StorageManager:
    def __init__(self):
        # åˆå§‹åŒ– Embedding
        self.embedding = OllamaEmbeddings(
            model=config.EMBED_MODEL_NAME,
            base_url=config.OLLAMA_BASE_URL
        )
        self.splitter_factory = TextSplitterFactory()
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.docstore = LocalFileStore(config.DOC_STORE_PATH)
        os.makedirs(config.PERSIST_DIR, exist_ok=True)

    def clear_data(self):
        """æ¸…ç©ºæ‰€æœ‰æœ¬åœ°ç´¢å¼•æ•°æ®"""
        if os.path.exists(config.PERSIST_DIR):
            shutil.rmtree(config.PERSIST_DIR)
        os.makedirs(config.PERSIST_DIR, exist_ok=True)

    # --- ä¿®å¤ï¼šè¡¥å…¨ç¼ºå¤±çš„ load_graph æ–¹æ³• ---
    def load_graph(self) -> nx.Graph:
        """ä»æœ¬åœ°æŒä¹…åŒ–æ–‡ä»¶åŠ è½½çŸ¥è¯†å›¾è°±"""
        if os.path.exists(config.GRAPH_PATH):
            try:
                with open(config.GRAPH_PATH, "rb") as f:
                    print(f"ğŸ•¸ï¸ æ­£åœ¨åŠ è½½çŸ¥è¯†å›¾è°±: {config.GRAPH_PATH}")
                    return pickle.load(f)
            except Exception as e:
                print(f"âš ï¸ å›¾è°±åŠ è½½å¤±è´¥: {e}, è¿”å›ç©ºå›¾")
                return nx.Graph()
        else:
            print("âš ï¸ æœªå‘ç°å›¾è°±æ–‡ä»¶ï¼Œåˆå§‹åŒ–æ–°å›¾è°±")
            return nx.Graph()

    def save_graph(self, graph: nx.Graph):
        """å°†çŸ¥è¯†å›¾è°±ä¿å­˜åˆ°æœ¬åœ°"""
        with open(config.GRAPH_PATH, "wb") as f:
            pickle.dump(graph, f)
            print(f"âœ… å›¾è°±å·²ä¿å­˜è‡³: {config.GRAPH_PATH}")

    def build_vector_bm25_index(self, docs: List[Document]):
        """æ„å»ºåŒè·¯ç´¢å¼•ï¼šChroma(å‘é‡) + BM25(å…³é”®è¯)"""
        # 1. åˆå§‹åŒ– Chroma
        vectorstore = Chroma(
            collection_name="rag_collection",
            embedding_function=self.embedding,
            persist_directory=config.DB_PATH
        )
        
        # 2. åˆå§‹åŒ–çˆ¶æ–‡æ¡£å­˜å‚¨ (ByteStore)
        doc_store = LocalFileStore(config.DOC_STORE_PATH)
        
        # 3. è¿è¡Œçˆ¶å­æ–‡æ¡£åˆ‡åˆ†é€»è¾‘
        retriever = SimpleParentRetriever(
            vectorstore=vectorstore, 
            docstore=doc_store,
            child_splitter=self.splitter_factory.get_child_splitter(),
            parent_splitter=self.splitter_factory.get_parent_splitter()
        )

        print(f"ğŸ’¾ æ­£åœ¨å‘é‡åŒ–å¹¶ç´¢å¼• {len(docs)} ä¸ªåŸå§‹æ–‡æ¡£...")
        retriever.add_documents(docs)

        # 4. æ„å»ºå¹¶ä¿å­˜ BM25 ç´¢å¼•
        print("ğŸ§® æ­£åœ¨æ„å»º BM25 å…³é”®è¯ç´¢å¼•...")
        all_data = vectorstore.get()
        if all_data['documents']:
            bm25_docs = [
                Document(page_content=d, metadata=m) 
                for d, m in zip(all_data['documents'], all_data['metadatas'])
            ]
            bm25_retriever = BM25Retriever.from_documents(bm25_docs)
            with open(config.BM25_PATH, "wb") as f:
                pickle.dump(bm25_retriever, f)
        print("âœ… å­˜å‚¨å±‚æ„å»ºæˆåŠŸï¼")

    def get_retriever_components(self):
        """ä¸ºå‰ç«¯æä¾›æ£€ç´¢æ‰€éœ€çš„å…¨éƒ¨ç‰©ç†ç»„ä»¶"""
        # åŠ è½½å‘é‡åº“
        vectorstore = Chroma(
            collection_name="rag_collection", 
            persist_directory=config.DB_PATH, 
            embedding_function=self.embedding
        )
        # åŠ è½½çˆ¶æ–‡æ¡£åº“
        doc_store = LocalFileStore(config.DOC_STORE_PATH)
        
        # åŠ è½½ BM25 (å¦‚æœå­˜åœ¨)
        bm25 = None
        if os.path.exists(config.BM25_PATH):
            try:
                with open(config.BM25_PATH, "rb") as f:
                    bm25 = pickle.load(f)
            except Exception as e:
                print(f"âš ï¸ BM25 åŠ è½½å¤±è´¥: {e}")
                
        return vectorstore, doc_store, bm25